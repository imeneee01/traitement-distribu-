{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a70df09d",
   "metadata": {},
   "source": [
    "## Lab1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c4726652",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, when, avg, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5619cff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark session created: <pyspark.sql.session.SparkSession object at 0x000001CE36D3FD50>\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"Projet-Final\").getOrCreate()\n",
    "print('Spark session created:', spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0ebc0427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----------+-----------------+-----------------+------------------+------------------+----------+-------------+------+\n",
      "|          timestamp|      date|      temperature|         pressure|         vibration|          humidity| equipment|     location|faulty|\n",
      "+-------------------+----------+-----------------+-----------------+------------------+------------------+----------+-------------+------+\n",
      "|2025-01-01 08:00:00|2025-01-01|58.18018003931781|25.02927765103301|0.6065162172245139|45.694907104076414|   Turbine|      Atlanta|   0.0|\n",
      "|2025-01-01 08:00:10|2025-01-01|75.74071220894001|22.95401759548667| 2.338094753751008| 41.86740679261492|Compressor|      Chicago|   0.0|\n",
      "|2025-01-01 08:00:20|2025-01-01|71.35859424081657|27.27683031893662|1.3891983049086754| 58.95440890948324|   Turbine|San Francisco|   0.0|\n",
      "|2025-01-01 08:00:30|2025-01-01|71.61698526704753|32.24292130393475|1.7706896863176191| 40.56513821185597|      Pump|      Atlanta|   0.0|\n",
      "|2025-01-01 08:00:40|2025-01-01|66.50683203881802|45.19747079743589|0.3453979892955756|43.253794756433095|      Pump|     New York|   0.0|\n",
      "+-------------------+----------+-----------------+-----------------+------------------+------------------+----------+-------------+------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(\"./data/equipment_anomaly_data.csv\", header=True, inferSchema=True)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ae467b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- date: date (nullable = true)\n",
      " |-- temperature: double (nullable = true)\n",
      " |-- pressure: double (nullable = true)\n",
      " |-- vibration: double (nullable = true)\n",
      " |-- humidity: double (nullable = true)\n",
      " |-- equipment: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- faulty: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "24055ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df.dropna(subset=[\"temperature\", \"pressure\", \"vibration\", \"humidity\", \"equipment\"])\n",
    "df_clean = df_clean.fillna({\"faulty\": 0.0})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d7f25d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----------+-----------------+-----------------+------------------+------------------+----------+-------------+------+---------------+\n",
      "|          timestamp|      date|      temperature|         pressure|         vibration|          humidity| equipment|     location|faulty|health_category|\n",
      "+-------------------+----------+-----------------+-----------------+------------------+------------------+----------+-------------+------+---------------+\n",
      "|2025-01-01 08:00:00|2025-01-01|58.18018003931781|25.02927765103301|0.6065162172245139|45.694907104076414|   Turbine|      Atlanta|   0.0|         normal|\n",
      "|2025-01-01 08:00:10|2025-01-01|75.74071220894001|22.95401759548667| 2.338094753751008| 41.86740679261492|Compressor|      Chicago|   0.0|         normal|\n",
      "|2025-01-01 08:00:20|2025-01-01|71.35859424081657|27.27683031893662|1.3891983049086754| 58.95440890948324|   Turbine|San Francisco|   0.0|         normal|\n",
      "|2025-01-01 08:00:30|2025-01-01|71.61698526704753|32.24292130393475|1.7706896863176191| 40.56513821185597|      Pump|      Atlanta|   0.0|         normal|\n",
      "|2025-01-01 08:00:40|2025-01-01|66.50683203881802|45.19747079743589|0.3453979892955756|43.253794756433095|      Pump|     New York|   0.0|         normal|\n",
      "+-------------------+----------+-----------------+-----------------+------------------+------------------+----------+-------------+------+---------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "df_enriched = df_clean.withColumn(\n",
    "    \"health_category\",\n",
    "    when((col(\"vibration\") < 50) & (col(\"temperature\") < 80) & (col(\"pressure\") < 200), \"normal\")\n",
    "    .when((col(\"vibration\") >= 50) & (col(\"vibration\") < 70), \"warning\")\n",
    "    .when((col(\"temperature\") >= 80) | (col(\"pressure\") >= 200) | (col(\"vibration\") >= 70), \"critical\")\n",
    "    .otherwise(\"unknown\")\n",
    ")\n",
    "df_enriched.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "55a3418d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------+------------------+-----------------+------------------+------------------+------------+\n",
      "| equipment|health_category|     avg_vibration|  avg_temperature|      avg_pressure|      avg_humidity|record_count|\n",
      "+----------+---------------+------------------+-----------------+------------------+------------------+------------+\n",
      "|   Turbine|       critical|  1.80083531490391|93.90281591073115| 37.76805313731594| 49.15736323471513|         452|\n",
      "|Compressor|       critical|1.7558697650204935| 93.2707744438854| 36.55402631824557|50.503897248017026|         526|\n",
      "|      Pump|         normal|1.5677290655300709|65.53427429076656|35.184459849628766|50.089306426076014|        2042|\n",
      "|   Turbine|         normal|1.5746258441308443|65.67025309635089|35.445976244629556| 49.78657371620923|        2113|\n",
      "|      Pump|       critical|1.8025541631446096|  91.800079163731|37.474128614717706|50.645782038507676|         492|\n",
      "+----------+---------------+------------------+-----------------+------------------+------------------+------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "df_agg = df_enriched.groupBy(\"equipment\", \"health_category\") \\\n",
    "    .agg(\n",
    "        avg(\"vibration\").alias(\"avg_vibration\"),\n",
    "        avg(\"temperature\").alias(\"avg_temperature\"),\n",
    "        avg(\"pressure\").alias(\"avg_pressure\"),\n",
    "        avg(\"humidity\").alias(\"avg_humidity\"),\n",
    "        count(\"*\").alias(\"record_count\")\n",
    "    )\n",
    "df_agg.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cfacc134",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg.write.mode(\"overwrite\").parquet(\"output_projet_final/equipment_health_agg.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3a8a9055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------+------------------+-----------------+------------------+------------------+------------+\n",
      "| equipment|health_category|     avg_vibration|  avg_temperature|      avg_pressure|      avg_humidity|record_count|\n",
      "+----------+---------------+------------------+-----------------+------------------+------------------+------------+\n",
      "|   Turbine|       critical|  1.80083531490391|93.90281591073115| 37.76805313731594| 49.15736323471513|         452|\n",
      "|Compressor|       critical|1.7558697650204935| 93.2707744438854| 36.55402631824557|50.503897248017026|         526|\n",
      "|      Pump|         normal|1.5677290655300709|65.53427429076656|35.184459849628766|50.089306426076014|        2042|\n",
      "|   Turbine|         normal|1.5746258441308443|65.67025309635089|35.445976244629556| 49.78657371620923|        2113|\n",
      "|      Pump|       critical|1.8025541631446096|  91.800079163731|37.474128614717706|50.645782038507676|         492|\n",
      "|Compressor|         normal|1.5695609646421145|65.88416239585283| 35.51658158641802| 50.09470231490039|        2047|\n",
      "+----------+---------------+------------------+-----------------+------------------+------------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_result = spark.read.parquet(\"output_projet_final/equipment_health_agg.parquet\")\n",
    "df_result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4be94a",
   "metadata": {},
   "source": [
    "## Lab2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1bdd9338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+-----+\n",
      "|hour| equipment|count|\n",
      "+----+----------+-----+\n",
      "|  16|Compressor|  122|\n",
      "|   8|      Pump|  106|\n",
      "|  16|   Turbine|  119|\n",
      "|  14|      Pump|  116|\n",
      "|  20|      Pump|  131|\n",
      "|   8|Compressor|  121|\n",
      "|  13|   Turbine|  115|\n",
      "|  16|      Pump|  119|\n",
      "|   4|Compressor|  126|\n",
      "|  22|   Turbine|  123|\n",
      "|   3|   Turbine|  116|\n",
      "|  17|      Pump|  117|\n",
      "|  21|   Turbine|  115|\n",
      "|   3|Compressor|  124|\n",
      "|  23|Compressor|  128|\n",
      "|  12|      Pump|  122|\n",
      "|   1|   Turbine|  124|\n",
      "|   2|   Turbine|  102|\n",
      "|  15|      Pump|  115|\n",
      "|  22|Compressor|  135|\n",
      "+----+----------+-----+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import hour, col\n",
    "\n",
    "df_grouped = df.groupBy(hour(col(\"timestamp\")).alias(\"hour\"), col(\"equipment\")).count()\n",
    "df_grouped.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b492776c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------+---------+------------+------------+----------------+\n",
      "|equipment_id|equipment_type| location|manufacturer|install_date|last_maintenance|\n",
      "+------------+--------------+---------+------------+------------+----------------+\n",
      "|      EQ-001|          Pump|Marseille|   Schneider|  2018-03-14|      2024-01-10|\n",
      "|      EQ-002|       Turbine|     Lyon|          GE|  2019-07-22|      2024-03-15|\n",
      "|      EQ-003|    Compressor|    Paris|     Siemens|  2020-11-05|      2024-04-18|\n",
      "|      EQ-004|        Boiler| Toulouse|         EDF|  2021-09-09|      2024-05-02|\n",
      "|      EQ-005|         Valve|    Lille|         ABB|  2018-12-17|      2024-02-12|\n",
      "+------------+--------------+---------+------------+------------+----------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "# Charger le CSV des métadonnées des équipements\n",
    "metadata_df = spark.read.csv(\"data/equipment_metadata.csv\", header=True, inferSchema=True)\n",
    "metadata_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e0d965c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+-----+------------+--------------+---------+------------+------------+----------------+\n",
      "|hour| equipment|count|equipment_id|equipment_type| location|manufacturer|install_date|last_maintenance|\n",
      "+----+----------+-----+------------+--------------+---------+------------+------------+----------------+\n",
      "|  16|Compressor|  122|      EQ-013|    Compressor|    Nancy|     Siemens|  2020-10-29|      2024-05-07|\n",
      "|  16|Compressor|  122|      EQ-003|    Compressor|    Paris|     Siemens|  2020-11-05|      2024-04-18|\n",
      "|   8|      Pump|  106|      EQ-001|          Pump|Marseille|   Schneider|  2018-03-14|      2024-01-10|\n",
      "|  16|   Turbine|  119|      EQ-012|       Turbine|    Paris|          GE|  2019-08-01|      2024-03-27|\n",
      "|  16|   Turbine|  119|      EQ-002|       Turbine|     Lyon|          GE|  2019-07-22|      2024-03-15|\n",
      "+----+----------+-----+------------+--------------+---------+------------+------------+----------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "df_enriched = df_grouped.join(metadata_df, df_grouped[\"equipment\"] == metadata_df[\"equipment_type\"], \"left\")\n",
    "df_enriched.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "de7e6a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_enriched.write \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .partitionBy(\"equipment\") \\\n",
    "    .parquet(\"output_projet_final/output_parquet_by_equipment\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b65b8d7",
   "metadata": {},
   "source": [
    "## Lab 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "894a541e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Parsed Logical Plan ==\n",
      "Join LeftOuter, (equipment#272 = equipment_type#1030)\n",
      ":- Aggregate [hour(timestamp#567, Some(Europe/Paris)), equipment#272], [hour(timestamp#567, Some(Europe/Paris)) AS hour#984, equipment#272, count(1) AS count#985L]\n",
      ":  +- Project [to_timestamp(timestamp#266, None, TimestampType, Some(Europe/Paris), true) AS timestamp#567, date#526, temperature#268, pressure#269, vibration#270, humidity#271, equipment#272, location#273, faulty#274, hour#527]\n",
      ":     +- Project [timestamp#266, date#526, temperature#268, pressure#269, vibration#270, humidity#271, equipment#272, location#273, faulty#274, hour(timestamp#266, Some(Europe/Paris)) AS hour#527]\n",
      ":        +- Project [timestamp#266, date_format(timestamp#266, yyyy-MM-dd, Some(Europe/Paris)) AS date#526, temperature#268, pressure#269, vibration#270, humidity#271, equipment#272, location#273, faulty#274, hour#525]\n",
      ":           +- Project [timestamp#266, date#524, temperature#268, pressure#269, vibration#270, humidity#271, equipment#272, location#273, faulty#274, hour(timestamp#266, Some(Europe/Paris)) AS hour#525]\n",
      ":              +- Project [timestamp#266, date_format(timestamp#266, yyyy-MM-dd, Some(Europe/Paris)) AS date#524, temperature#268, pressure#269, vibration#270, humidity#271, equipment#272, location#273, faulty#274]\n",
      ":                 +- Relation [timestamp#266,date#267,temperature#268,pressure#269,vibration#270,humidity#271,equipment#272,location#273,faulty#274] csv\n",
      "+- Relation [equipment_id#1029,equipment_type#1030,location#1031,manufacturer#1032,install_date#1033,last_maintenance#1034] csv\n",
      "\n",
      "== Analyzed Logical Plan ==\n",
      "hour: int, equipment: string, count: bigint, equipment_id: string, equipment_type: string, location: string, manufacturer: string, install_date: date, last_maintenance: date\n",
      "Join LeftOuter, (equipment#272 = equipment_type#1030)\n",
      ":- Aggregate [hour(timestamp#567, Some(Europe/Paris)), equipment#272], [hour(timestamp#567, Some(Europe/Paris)) AS hour#984, equipment#272, count(1) AS count#985L]\n",
      ":  +- Project [to_timestamp(timestamp#266, None, TimestampType, Some(Europe/Paris), true) AS timestamp#567, date#526, temperature#268, pressure#269, vibration#270, humidity#271, equipment#272, location#273, faulty#274, hour#527]\n",
      ":     +- Project [timestamp#266, date#526, temperature#268, pressure#269, vibration#270, humidity#271, equipment#272, location#273, faulty#274, hour(timestamp#266, Some(Europe/Paris)) AS hour#527]\n",
      ":        +- Project [timestamp#266, date_format(timestamp#266, yyyy-MM-dd, Some(Europe/Paris)) AS date#526, temperature#268, pressure#269, vibration#270, humidity#271, equipment#272, location#273, faulty#274, hour#525]\n",
      ":           +- Project [timestamp#266, date#524, temperature#268, pressure#269, vibration#270, humidity#271, equipment#272, location#273, faulty#274, hour(timestamp#266, Some(Europe/Paris)) AS hour#525]\n",
      ":              +- Project [timestamp#266, date_format(timestamp#266, yyyy-MM-dd, Some(Europe/Paris)) AS date#524, temperature#268, pressure#269, vibration#270, humidity#271, equipment#272, location#273, faulty#274]\n",
      ":                 +- Relation [timestamp#266,date#267,temperature#268,pressure#269,vibration#270,humidity#271,equipment#272,location#273,faulty#274] csv\n",
      "+- Relation [equipment_id#1029,equipment_type#1030,location#1031,manufacturer#1032,install_date#1033,last_maintenance#1034] csv\n",
      "\n",
      "== Optimized Logical Plan ==\n",
      "Join LeftOuter, (equipment#272 = equipment_type#1030)\n",
      ":- Aggregate [_groupingexpression#1146, equipment#272], [_groupingexpression#1146 AS hour#984, equipment#272, count(1) AS count#985L]\n",
      ":  +- Project [equipment#272, hour(timestamp#266, Some(Europe/Paris)) AS _groupingexpression#1146]\n",
      ":     +- Relation [timestamp#266,date#267,temperature#268,pressure#269,vibration#270,humidity#271,equipment#272,location#273,faulty#274] csv\n",
      "+- Filter isnotnull(equipment_type#1030)\n",
      "   +- Relation [equipment_id#1029,equipment_type#1030,location#1031,manufacturer#1032,install_date#1033,last_maintenance#1034] csv\n",
      "\n",
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- BroadcastHashJoin [equipment#272], [equipment_type#1030], LeftOuter, BuildRight, false\n",
      "   :- HashAggregate(keys=[_groupingexpression#1146, equipment#272], functions=[count(1)], output=[hour#984, equipment#272, count#985L])\n",
      "   :  +- Exchange hashpartitioning(_groupingexpression#1146, equipment#272, 200), ENSURE_REQUIREMENTS, [plan_id=1380]\n",
      "   :     +- HashAggregate(keys=[_groupingexpression#1146, equipment#272], functions=[partial_count(1)], output=[_groupingexpression#1146, equipment#272, count#1002L])\n",
      "   :        +- Project [equipment#272, hour(timestamp#266, Some(Europe/Paris)) AS _groupingexpression#1146]\n",
      "   :           +- FileScan csv [timestamp#266,equipment#272] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/c:/Users/imene/Desktop/ecole/ecole/M2/traitement-distribué/data/..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<timestamp:timestamp,equipment:string>\n",
      "   +- BroadcastExchange HashedRelationBroadcastMode(List(input[1, string, false]),false), [plan_id=1383]\n",
      "      +- Filter isnotnull(equipment_type#1030)\n",
      "         +- FileScan csv [equipment_id#1029,equipment_type#1030,location#1031,manufacturer#1032,install_date#1033,last_maintenance#1034] Batched: false, DataFilters: [isnotnull(equipment_type#1030)], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/c:/Users/imene/Desktop/ecole/ecole/M2/traitement-distribué/data/..., PartitionFilters: [], PushedFilters: [IsNotNull(equipment_type)], ReadSchema: struct<equipment_id:string,equipment_type:string,location:string,manufacturer:string,install_date...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_enriched.explain(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "67c2024e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+-----+------------+--------------+---------+------------+------------+----------------+\n",
      "|hour|equipment|count|equipment_id|equipment_type| location|manufacturer|install_date|last_maintenance|\n",
      "+----+---------+-----+------------+--------------+---------+------------+------------+----------------+\n",
      "|   8|     Pump|  106|      EQ-001|          Pump|Marseille|   Schneider|  2018-03-14|      2024-01-10|\n",
      "|  14|     Pump|  116|      EQ-001|          Pump|Marseille|   Schneider|  2018-03-14|      2024-01-10|\n",
      "|  20|     Pump|  131|      EQ-001|          Pump|Marseille|   Schneider|  2018-03-14|      2024-01-10|\n",
      "|  16|     Pump|  119|      EQ-001|          Pump|Marseille|   Schneider|  2018-03-14|      2024-01-10|\n",
      "|  17|     Pump|  117|      EQ-001|          Pump|Marseille|   Schneider|  2018-03-14|      2024-01-10|\n",
      "+----+---------+-----+------------+--------------+---------+------------+------------+----------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "df_repart = df_enriched.repartition(\"equipment\")\n",
    "df_repart.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d9e0ccbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+-----+------------+--------------+---------+------------+------------+----------------+\n",
      "|hour| equipment|count|equipment_id|equipment_type| location|manufacturer|install_date|last_maintenance|\n",
      "+----+----------+-----+------------+--------------+---------+------------+------------+----------------+\n",
      "|  16|Compressor|  122|      EQ-013|    Compressor|    Nancy|     Siemens|  2020-10-29|      2024-05-07|\n",
      "|  16|Compressor|  122|      EQ-003|    Compressor|    Paris|     Siemens|  2020-11-05|      2024-04-18|\n",
      "|   8|      Pump|  106|      EQ-001|          Pump|Marseille|   Schneider|  2018-03-14|      2024-01-10|\n",
      "|  16|   Turbine|  119|      EQ-012|       Turbine|    Paris|          GE|  2019-08-01|      2024-03-27|\n",
      "|  16|   Turbine|  119|      EQ-002|       Turbine|     Lyon|          GE|  2019-07-22|      2024-03-15|\n",
      "+----+----------+-----+------------+--------------+---------+------------+------------+----------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import broadcast\n",
    "\n",
    "df_final = df_grouped.join(broadcast(metadata_df), df_grouped[\"equipment\"] == metadata_df[\"equipment_type\"], how=\"left\")\n",
    "df_final.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5eb2e9e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[hour: int, equipment: string, count: bigint, equipment_id: string, equipment_type: string, location: string, manufacturer: string, install_date: date, last_maintenance: date]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_enriched.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cc8299f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[hour: int, equipment: string, count: bigint, equipment_id: string, equipment_type: string, location: string, manufacturer: string, install_date: date, last_maintenance: date]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sparkContext.setCheckpointDir(\"output_projet_final/checkpoints\")\n",
    "df_enriched.checkpoint(eager=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4bdb289a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avant optimisation : 3.208066463470459 secondes\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "df_enriched.count()\n",
    "end = time.time()\n",
    "print(\"Avant optimisation :\", end-start, \"secondes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "90137f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Après optimisation : 1.4035847187042236 secondes\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "df_final.count()\n",
    "end = time.time()\n",
    "print(\"Après optimisation :\", end-start, \"secondes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7328c5ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
